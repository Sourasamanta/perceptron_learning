# perceptron_learning
It is a perceptron learning simulation made in Kotlin

---

# ğŸ” Perceptron Learning in Java and kotlin

A simple **Perceptron implementation** in Java and kotlin for binary classification problems. This project demonstrates the fundamental building blocks of a single-layer neural network, including weight updates, bias adjustment, and iterative training.

---

## ğŸš€ Features

âœ… Supports arbitrary input size
âœ… Binary classification using -1/1 convention
âœ… Adjustable learning rate
âœ… Predict function for inference
âœ… Train function with iterative weight updates until convergence
âœ… Access to learned weights and bias after training

---

## ğŸ“‚ Project Structure

```
â”œâ”€â”€ Perceptron.java       # Core perceptron implementation
â”œâ”€â”€ Main.java             # Sample usage / test cases
â”œâ”€â”€ README.md             # Documentation (this file)
```

---

## ğŸ› ï¸ How to Compile and Run

### ğŸ§± Compile

```bash
javac Perceptron.java Main.java
```

### â–¶ï¸ Run

```bash
java Main
```

Ensure your `Main.java` includes example inputs for training and prediction.

---

## ğŸ§ª Test Cases

### âœ… Test Case 1: AND Logic

```java
int[][] inputs = {{0,0}, {0,1}, {1,0}, {1,1}};
int[] targets = {-1, -1, -1, 1};
Perceptron p = new Perceptron(2, 0.1);
for(int i=0;i<inputs.length;i++) p.train(inputs[i], targets[i]);
```

**Output:** Correct predictions for AND logic after training.

### âœ… Test Case 2: OR Logic

```java
int[][] inputs = {{0,0}, {0,1}, {1,0}, {1,1}};
int[] targets = {-1, 1, 1, 1};
Perceptron p = new Perceptron(2, 0.1);
for(int i=0;i<inputs.length;i++) p.train(inputs[i], targets[i]);
```

**Output:** Correct predictions for OR logic after training.

### âš ï¸ Limitations

* Only single-layer perceptron (cannot solve non-linearly separable problems like XOR)
* Input features must be numeric and preprocessed appropriately
* No batch training â€” updates are made per sample
* No advanced optimization or momentum

---

## ğŸ§¾ Sample Output

```
Training perceptron for AND logic...
Predicted output for [0,1]: -1
Predicted output for [1,1]: 1
Final weights: [0.1, 0.1]
Final bias: -0.05
```

---

## ğŸ‘¨â€ğŸ’» Author

**Sourajit Samanta**
Machine Learning & Neural Networks Enthusiast | BTech CSE

---
